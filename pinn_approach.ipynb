{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4fd3b237",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "58ab0e34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on: cpu\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Check for GPU\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Running on: {device}\")\n",
    "\n",
    "# --- 1. The Neural Network Model ---\n",
    "class PINN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(PINN, self).__init__()\n",
    "        # Architecture: 2 inputs -> 5 layers of 20 neurons -> 1 output\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(2, 20), nn.Tanh(),\n",
    "            nn.Linear(20, 20), nn.Tanh(),\n",
    "            nn.Linear(20, 20), nn.Tanh(),\n",
    "            nn.Linear(20, 20), nn.Tanh(),\n",
    "            nn.Linear(20, 20), nn.Tanh(),\n",
    "            nn.Linear(20, 1)\n",
    "        )\n",
    "\n",
    "    def forward(self, x, y):\n",
    "        inputs = torch.cat([x, y], dim=1)\n",
    "        return self.net(inputs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a93fa1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# --- 2. Physics & Data Generation Functions ---\n",
    "\n",
    "def compute_derivatives(model, x, y):\n",
    "    \"\"\"\n",
    "    Helper to compute V and its derivatives (first and second)\n",
    "    needed for PDE residuals and Neumann BCs.\n",
    "    \"\"\"\n",
    "    x.requires_grad = True\n",
    "    y.requires_grad = True\n",
    "    V = model(x, y)\n",
    "\n",
    "    # First derivatives\n",
    "    grads = torch.autograd.grad(V, [x, y], grad_outputs=torch.ones_like(V),\n",
    "                                create_graph=True, retain_graph=True)\n",
    "    dV_dx, dV_dy = grads[0], grads[1]\n",
    "\n",
    "    # Second derivatives\n",
    "    d2V_dx2 = torch.autograd.grad(dV_dx, x, grad_outputs=torch.ones_like(dV_dx),\n",
    "                                  create_graph=True, retain_graph=True)[0]\n",
    "    d2V_dy2 = torch.autograd.grad(dV_dy, y, grad_outputs=torch.ones_like(dV_dy),\n",
    "                                  create_graph=True, retain_graph=True)[0]\n",
    "\n",
    "    return V, dV_dx, dV_dy, d2V_dx2, d2V_dy2\n",
    "\n",
    "def get_boundary_data(N_b, L, Vmax, k_vals, bc_type_right='dirichlet'):\n",
    "    \"\"\"\n",
    "    Generates training data for the 4 boundaries.\n",
    "    bc_type_right: 'dirichlet' or 'neumann' (for Task 2)\n",
    "    \"\"\"\n",
    "    k1, k2, k3, k4 = k_vals\n",
    "\n",
    "    # -- Coordinates --\n",
    "    # Left (-L, y), Right (L, y), Bottom (x, -L), Top (x, L)\n",
    "    y_side = torch.rand(N_b, 1) * 2 * L - L\n",
    "    x_side = torch.ones_like(y_side)\n",
    "\n",
    "    x_flat = torch.rand(N_b, 1) * 2 * L - L\n",
    "    y_flat = torch.ones_like(x_flat)\n",
    "\n",
    "    # 1. Left Boundary (x = -L) - Dirichlet\n",
    "    x_l = -L * x_side\n",
    "    y_l = y_side\n",
    "    v_l = Vmax * torch.sin(k1 * np.pi * (y_l + L) / (2 * L))\n",
    "\n",
    "    # 2. Right Boundary (x = L) - Dirichlet OR Neumann\n",
    "    x_r = L * x_side\n",
    "    y_r = y_side\n",
    "\n",
    "    if bc_type_right == 'dirichlet':\n",
    "        # Standard value assignment\n",
    "        target_r = Vmax * torch.sin(k3 * np.pi * (y_r + L) / (2 * L))\n",
    "    else:\n",
    "        # For Neumann (Task 2), target is the GRADIENT value.\n",
    "        # C++ code implies dV/dx = 0 (v[N-1] = v[N-2])\n",
    "        target_r = torch.zeros_like(y_r)\n",
    "\n",
    "    # 3. Bottom Boundary (y = -L) - Dirichlet\n",
    "    x_b = x_flat\n",
    "    y_b = -L * y_flat\n",
    "    v_b = Vmax * torch.sin(k4 * np.pi * (x_b + L) / (2 * L))\n",
    "\n",
    "    # 4. Top Boundary (y = L) - Dirichlet\n",
    "    x_t = x_flat\n",
    "    y_t = L * y_flat\n",
    "    v_t = Vmax * torch.sin(k2 * np.pi * (x_t + L) / (2 * L))\n",
    "\n",
    "    # Package into a dictionary for easier handling in the training loop\n",
    "    data = {\n",
    "        'left': (x_l.to(device), y_l.to(device), v_l.to(device)),\n",
    "        'right': (x_r.to(device), y_r.to(device), target_r.to(device)),\n",
    "        'bottom': (x_b.to(device), y_b.to(device), v_b.to(device)),\n",
    "        'top': (x_t.to(device), y_t.to(device), v_t.to(device))\n",
    "    }\n",
    "    return data\n",
    "\n",
    "def get_collocation_points(N_c, L):\n",
    "    x_c = (torch.rand(N_c, 1) * 2 * L - L).to(device)\n",
    "    y_c = (torch.rand(N_c, 1) * 2 * L - L).to(device)\n",
    "    return x_c, y_c\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d917d64d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# --- 3. Modular Training Function ---\n",
    "\n",
    "def run_task(task_name, Arho, k_vals, bc_type_right, epochs=6000):\n",
    "    print(f\"\\n--- Running {task_name} ---\")\n",
    "    print(f\"Params: Arho={Arho}, k={k_vals}, Right BC={bc_type_right}\")\n",
    "\n",
    "    # Physics constants\n",
    "    L = 4.0\n",
    "    epsilon = 1.0\n",
    "    Vmax = 1.0\n",
    "\n",
    "    model = PINN().to(device)\n",
    "    optimizer = optim.Adam(model.parameters(), lr=1e-3)\n",
    "    loss_history = []\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # --- A. Boundary Loss ---\n",
    "        bc_data = get_boundary_data(200, L, Vmax, k_vals, bc_type_right)\n",
    "        loss_bc = 0.0\n",
    "\n",
    "        # Dirichlet Boundaries (Left, Top, Bottom)\n",
    "        for side in ['left', 'top', 'bottom']:\n",
    "            xb, yb, vb_target = bc_data[side]\n",
    "            vb_pred = model(xb, yb)\n",
    "            loss_bc += torch.mean((vb_pred - vb_target)**2)\n",
    "\n",
    "        # Right Boundary (Dirichlet or Neumann)\n",
    "        xb, yb, target_r = bc_data['right']\n",
    "        if bc_type_right == 'dirichlet':\n",
    "            vb_pred = model(xb, yb)\n",
    "            loss_bc += torch.mean((vb_pred - target_r)**2)\n",
    "        else:\n",
    "            # Neumann: Calculate dV/dx at boundary and compare to target (0)\n",
    "            # We must use compute_derivatives to get gradients\n",
    "            _, dV_dx, _, _, _ = compute_derivatives(model, xb, yb)\n",
    "            loss_bc += torch.mean((dV_dx - target_r)**2)\n",
    "\n",
    "        # --- B. PDE Residual Loss ---\n",
    "        xc, yc = get_collocation_points(2000, L)\n",
    "        _, _, _, d2V_dx2, d2V_dy2 = compute_derivatives(model, xc, yc)\n",
    "\n",
    "        # Charge Density Equation\n",
    "        rho = Arho * xc * yc * torch.exp(-(xc**2 + yc**2))\n",
    "\n",
    "        # Residual = Laplacian(V) + rho/epsilon\n",
    "        residual = d2V_dx2 + d2V_dy2 + (rho / epsilon)\n",
    "        loss_pde = torch.mean(residual**2)\n",
    "\n",
    "        # --- Total Loss ---\n",
    "        total_loss = loss_bc + loss_pde\n",
    "        total_loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        loss_history.append(total_loss.item())\n",
    "\n",
    "        if epoch % 1000 == 0:\n",
    "            print(f\"Epoch {epoch}: Loss {total_loss.item():.5f} (BC={loss_bc.item():.5f}, PDE={loss_pde.item():.5f})\")\n",
    "\n",
    "    # --- Saving Results ---\n",
    "    save_results(model, loss_history, task_name, L)\n",
    "\n",
    "def save_results(model, history, task_name, L):\n",
    "    # 1. Generate Grid Prediction\n",
    "    N_plot = 100\n",
    "    x_np = np.linspace(-L, L, N_plot)\n",
    "    y_np = np.linspace(-L, L, N_plot)\n",
    "    X, Y = np.meshgrid(x_np, y_np)\n",
    "\n",
    "    x_flat = torch.tensor(X.flatten(), dtype=torch.float32).unsqueeze(1).to(device)\n",
    "    y_flat = torch.tensor(Y.flatten(), dtype=torch.float32).unsqueeze(1).to(device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        V_pred = model(x_flat, y_flat).cpu().numpy().reshape(N_plot, N_plot)\n",
    "\n",
    "    # 2. Plotting\n",
    "    fig, ax = plt.subplots(1, 2, figsize=(14, 6))\n",
    "\n",
    "    # Potential Map\n",
    "    c1 = ax[0].imshow(V_pred, extent=[-L, L, -L, L], origin='lower', cmap='seismic')\n",
    "    ax[0].set_title(f'{task_name}: Potential V(x,y)')\n",
    "    ax[0].set_xlabel('x')\n",
    "    ax[0].set_ylabel('y')\n",
    "    plt.colorbar(c1, ax=ax[0])\n",
    "\n",
    "    # Convergence\n",
    "    ax[1].plot(history)\n",
    "    ax[1].set_yscale('log')\n",
    "    ax[1].set_title(f'{task_name}: Loss Convergence')\n",
    "    ax[1].set_xlabel('Epoch')\n",
    "    ax[1].set_ylabel('Total Loss (MSE)')\n",
    "    ax[1].grid(True, which=\"both\", ls=\"-\", alpha=0.5)\n",
    "\n",
    "    # Save\n",
    "    filename = f\"PINN_result_{task_name}.png\"\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(filename)\n",
    "    print(f\"Saved plot to {filename}\")\n",
    "    plt.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1046c2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Running Task1 ---\n",
      "Params: Arho=0.0, k=(1, -1, 1, -1), Right BC=dirichlet\n",
      "Epoch 0: Loss 2.09834 (BC=2.09810, PDE=0.00024)\n",
      "Epoch 1000: Loss 0.00192 (BC=0.00012, PDE=0.00180)\n",
      "Epoch 2000: Loss 0.00103 (BC=0.00016, PDE=0.00086)\n",
      "Epoch 3000: Loss 0.00176 (BC=0.00120, PDE=0.00056)\n",
      "Epoch 4000: Loss 0.00065 (BC=0.00017, PDE=0.00048)\n",
      "Epoch 5000: Loss 0.00050 (BC=0.00012, PDE=0.00038)\n",
      "Saved plot to PINN_result_Task1.png\n",
      "\n",
      "--- Running Task2_Neumann ---\n",
      "Params: Arho=0.0, k=(1, -1, 1, -1), Right BC=neumann\n",
      "Epoch 0: Loss 1.99104 (BC=1.99097, PDE=0.00007)\n",
      "Epoch 1000: Loss 0.00407 (BC=0.00145, PDE=0.00262)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# --- 4. Main Execution ---\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Parameters from C++ code [cite: 34, 107, 217]\n",
    "\n",
    "    # Task 1: Laplace (Arho=0), Dirichlet\n",
    "    # k values: 1, -1, 1, -1 (Left, Top, Right, Bottom mappings roughly)\n",
    "    run_task(task_name=\"Task1\",\n",
    "             Arho=0.0,\n",
    "             k_vals=(1, -1, 1, -1),\n",
    "             bc_type_right='dirichlet')\n",
    "\n",
    "    # Task 2: Laplace (Arho=0), Neumann on Right\n",
    "    # Same k values, but right boundary is overridden by Neumann logic\n",
    "    run_task(task_name=\"Task2_Neumann\",\n",
    "             Arho=0.0,\n",
    "             k_vals=(1, -1, 1, -1),\n",
    "             bc_type_right='neumann')\n",
    "\n",
    "    # Task 4a: Poisson (Arho=1), Zero Dirichlet BCs (k=0)\n",
    "    run_task(task_name=\"Task4a\",\n",
    "             Arho=1.0,\n",
    "             k_vals=(0, 0, 0, 0),\n",
    "             bc_type_right='dirichlet')\n",
    "\n",
    "    # Task 4b: Poisson (Arho=1), Standard Dirichlet BCs\n",
    "    run_task(task_name=\"Task4b\",\n",
    "             Arho=1.0,\n",
    "             k_vals=(1, -1, 1, -1),\n",
    "             bc_type_right='dirichlet')\n",
    "\n",
    "    print(\"\\nAll PINN tasks completed. Plots saved.\")\n",
    "\n",
    "\n",
    "    # Plotting\n",
    "    fig, ax = plt.subplots(1, 2, figsize=(14, 6))\n",
    "\n",
    "    # Plot 1: PINN Predicted Potential\n",
    "    c1 = ax[0].imshow(V_pred, extent=[-L, L, -L, L], origin='lower', cmap='seismic')\n",
    "    ax[0].set_title(f'PINN Predicted Potential V(x,y)\\n(Task 4b, Arho={Arho})')\n",
    "    ax[0].set_xlabel('x')\n",
    "    ax[0].set_ylabel('y')\n",
    "    plt.colorbar(c1, ax=ax[0])\n",
    "\n",
    "    # Plot 2: Training Loss\n",
    "    ax[1].plot(history)\n",
    "    ax[1].set_yscale('log')\n",
    "    ax[1].set_title('Training Loss Convergence')\n",
    "    ax[1].set_xlabel('Epoch')\n",
    "    ax[1].set_ylabel('Total Loss (MSE)')\n",
    "    ax[1].grid(True, which=\"both\", ls=\"-\", alpha=0.5)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    print(\"Training complete. You can see that without a mesh, the Neural Network\")\n",
    "    print(\"has learned the complex potential distribution solely from the\")\n",
    "    print(\"boundary equations and the charge density formula.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
